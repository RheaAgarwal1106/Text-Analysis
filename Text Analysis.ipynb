{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webscrapping and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import Request\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"C:\\IIT BSc. Data Science and Programming\\Internships\\Input.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_df = pd.read_excel(\"C:\\IIT BSc. Data Science and Programming\\Internships\\Output.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "url = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#webscrapping and saving articles as text files\n",
    "\n",
    "\n",
    "for i in df['URL']:\n",
    "    raw_request = Request(i)\n",
    "    raw_request.add_header('User-Agent', 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:78.0) Gecko/20100101 Firefox/78.0')\n",
    "    raw_request.add_header('Accept', 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8')\n",
    "    resp = urlopen(raw_request) #opening url\n",
    "    raw_html = resp.read() #reading the content\n",
    "    soup = BeautifulSoup(raw_html, 'html.parser') #creating beautiful soup object\n",
    "    count = count+1\n",
    "    zeug = [x.get_text() for x in soup.find_all('div', attrs={'class': 'td-post-content'})]  \n",
    "    #getting the required article which was under div tag with class td-post-content\n",
    "    string = ''\n",
    "    for i in zeug:\n",
    "        string = i+string       #obtaining the article in a readable format\n",
    "    \n",
    "    #saving the file\n",
    "    file = open(f'{url}.txt','w',encoding = 'utf-8') \n",
    "    file.write(string)\n",
    "    file.close()\n",
    "    url = url+1\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtaining the list of stopwords (alternative approach: nltk.corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the stopwords file\n",
    "\n",
    "file1 = open(\"C:\\IIT BSc. Data Science and Programming\\Internships\\StopWords_GenericLong.txt\",'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the stopwords file provided in the google drive\n",
    "\n",
    "stopwords = file1.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtaining a list of stopwords\n",
    "\n",
    "general_stopwords_list = []\n",
    "for i in stopwords:\n",
    "    x = i.replace('\\n','')\n",
    "    general_stopwords_list.append(x)\n",
    "general_stopwords_list[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Code for cleaning the text for all 150 links. Calculate Scores before last print statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining function for obtaining necessary part of the text, removing spaces at beginning\n",
    "\n",
    "def setup(txt):\n",
    "    li = []\n",
    "    for i in txt:\n",
    "        x = i.split()\n",
    "        li.append(x)\n",
    "    subl = [subl for subl in li if len(subl)!=0 ]\n",
    "    subl = subl[:-1]\n",
    "    text = subl\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for cleaning (punctuations,converting to lower case, filtering stopwords )\n",
    "def transform (text):\n",
    "    review = re.sub('[^a-zA-Z0-9]',' ', str(text))\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [word for word in review if word not in stopwords.words ('english')]\n",
    "    review = ' '.join(review)\n",
    "    return review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the file of positive and negative words in google drive\n",
    "\n",
    "posfile = open(\"C:\\IIT BSc. Data Science and Programming\\Internships\\positive-words.txt\",'r')\n",
    "negfile = open(\"C:\\\\IIT BSc. Data Science and Programming\\\\Internships\\\\negative-words.txt\",'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the files containing positive, negative words\n",
    "\n",
    "pos = posfile.readlines()\n",
    "neg = negfile.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtaining the positive and negative words in desired format (2 separate lists, words separated by comma, removing unnecessary spaces)\n",
    "\n",
    "pos_list = []\n",
    "for i in pos:\n",
    "    pos_list.append(i.replace('\\n',''))\n",
    "    \n",
    "neg_list = []\n",
    "for i in neg:\n",
    "    neg_list.append(i.replace('\\n',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a+', 'abound', 'abounds', 'abundance', 'abundant']\n"
     ]
    }
   ],
   "source": [
    "print(pos_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2-faced', '2-faces', 'abnormal', 'abolish', 'abominable']\n"
     ]
    }
   ],
   "source": [
    "print(neg_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for obtaining positive score (+1 is assigned to all the  words, their frequencies are calculated)\n",
    "\n",
    "def pos_score(trans):\n",
    "    pos_score = 0\n",
    "    st = trans\n",
    "    dic_pos = {} #creates an empty dictionary\n",
    "    count = 0\n",
    "    for i in st.split(' '):\n",
    "        if i in dic_pos and i in pos_list:            #forming a dictionary containing frequencies of positive words\n",
    "            dic_pos[i] = dic_pos[i]+1\n",
    "        elif i not in dic_pos and i in pos_list:\n",
    "            dic_pos[i] = 1\n",
    "    for i in dic_pos:\n",
    "        pos_score = pos_score + dic_pos[i]           #positive score = 1* frequency of positive words occuring\n",
    "    return pos_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function  for obtaining negative score (-1 is assigned to all the words, their frequencies are calculated)\n",
    "\n",
    "def neg_score(trans):\n",
    "    neg_score = 0\n",
    "    st = trans\n",
    "    dic_neg = {} #creates an empty dictionary\n",
    "    count = 0\n",
    "    for i in st.split(' '):\n",
    "        if i in dic_neg and i in neg_list:            #forming a dctionary containing frequencies of negative words\n",
    "            dic_neg[i] = dic_neg[i]+1\n",
    "        elif i not in dic_neg and i in neg_list:\n",
    "            dic_neg[i] = 1\n",
    "    for i in dic_neg:\n",
    "        neg_score = neg_score + dic_neg[i]            #negative score is -(-1)* frequncy of negative words\n",
    "    return neg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for calculating average sentence length\n",
    "\n",
    "def av_sen_length(set_up):\n",
    "    con = ''\n",
    "    for i in set_up:\n",
    "        for j in i:\n",
    "            con = con+' '+j\n",
    "    con = con.strip()\n",
    "    from nltk import tokenize\n",
    "    p = con\n",
    "\n",
    "    sen = tokenize.sent_tokenize(p)      #the article is tokenized first to obtaining a list separated by different sentences\n",
    "    \n",
    "    #sentence count\n",
    "    sencount = 0\n",
    "    for i in sen:\n",
    "        sencount = sencount + 1\n",
    "        \n",
    "    #words count\n",
    "    wordcount=0\n",
    "    for  i in set_up:  \n",
    "            for j in i:\n",
    "                wordcount = wordcount + 1\n",
    "                \n",
    "    #average sentence length\n",
    "    av_sen_len = wordcount/sencount\n",
    "    \n",
    "    return av_sen_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#module for tokenizing on the basis of syllables\n",
    "\n",
    "from nltk.tokenize.sonority_sequencing import SyllableTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a function to obtain complex words (syllables more than 2)\n",
    "\n",
    "def hardword():\n",
    "    words = ''\n",
    "    hardwordlist = []\n",
    "    l = []\n",
    "\n",
    "        # Create a reference variable for Class word_tokenize to split the word on the basis of syllables\n",
    "    tk = SyllableTokenizer()                        \n",
    "\n",
    "        # Create a string input\n",
    "    syllable = []\n",
    "    for i in trans.split(' '):\n",
    "        for j in i.split(' '):\n",
    "            if j.isalpha():                   #syllable is a list which stores the words as separate lists split by the syllable\n",
    "                syllable.append(tk.tokenize(j)) \n",
    "    syllable            \n",
    "    for i in syllable:\n",
    "        if len(i)>2:                          #retaining only the syllables which have more than 2 syllables\n",
    "            l.append(i)\n",
    "    for i in l:\n",
    "        hardwordlist.append(''.join(i))\n",
    "    return hardwordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words count original text\n",
    "def count(set_up):\n",
    "    wordcount=0\n",
    "    for  i in set_up:  \n",
    "            for j in i:\n",
    "                wordcount = wordcount + 1\n",
    "    return wordcount            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syllablecountperword(trans):\n",
    "    tk = SyllableTokenizer()\n",
    "\n",
    "        # Create a string input\n",
    "    syllable = []\n",
    "    for i in trans.split(' '):\n",
    "        for j in i.split(' '):\n",
    "            if j.isalpha():                   #syllable is a list which stores the words as separate lists split by the syllable\n",
    "                syllable.append(tk.tokenize(j))  \n",
    "                \n",
    "    syllablelen = 0\n",
    "    for i in syllable:\n",
    "        syllablelen = syllablelen + len(i)     #total number of syllables present in overall text/number of words (analysis done after cleaning text)\n",
    "    syllable_length = syllablelen/len(syllable)\n",
    "    return syllable_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averagewordlength(set_up):\n",
    "    wordsnum = count(set_up)\n",
    "    length = 0\n",
    "    for i in set_up:\n",
    "        for j in i:\n",
    "            length = length+len(j)\n",
    "    return length/wordsnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining function to calculate number of pronouns\n",
    "\n",
    "def pronouns(set_up):\n",
    "    para=''\n",
    "    for i in set_up:\n",
    "        for j in i:\n",
    "            para = para+' '+j\n",
    "            \n",
    "    para = para.strip().split(' ')     #obtaining a list of words in the article\n",
    "    \n",
    "    import re\n",
    "\n",
    "    i = re.findall(\"I\", str(para))\n",
    "    we = re.findall(\"we\", str(para))   #using re module we find if prounouns are present (considering upper and lower cases)\n",
    "    We = re.findall(\"We\", str(para))\n",
    "    ours = re.findall(\"ours\", str(para))\n",
    "    Ours = re.findall(\"Ours\", str(para))\n",
    "    us = re.findall(\"us\", str(para))\n",
    "    lengths = len(i) + len(we) + len(We) + len(ours) + len(Ours) + len(us)\n",
    "    return lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-f357201dfcb0>:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  answer_df['POSITIVE SCORE'][num-1] = round(li[0], 2)\n",
      "<ipython-input-21-f357201dfcb0>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  answer_df['NEGATIVE SCORE'][[num-1]] = round(li[1], 2)\n",
      "C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n",
      "<ipython-input-21-f357201dfcb0>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  answer_df['POLARITY SCORE'][num-1] = round(li[2], 2)\n",
      "<ipython-input-21-f357201dfcb0>:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  answer_df['SUBJECTIVITY SCORE'][num-1] = round(li[3], 2)\n",
      "<ipython-input-21-f357201dfcb0>:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  answer_df['AVG SENTENCE LENGTH'][num-1] = round(li[4], 2)\n",
      "<ipython-input-21-f357201dfcb0>:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  answer_df['PERCENTAGE OF COMPLEX WORDS'][num-1] = round(li[5], 2)\n",
      "<ipython-input-21-f357201dfcb0>:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  answer_df['FOG INDEX'][num-1] = round(li[6], 2)\n",
      "<ipython-input-21-f357201dfcb0>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  answer_df['AVG NUMBER OF WORDS PER SENTENCE'][num-1] = round(li[7],2)\n",
      "<ipython-input-21-f357201dfcb0>:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  answer_df['COMPLEX WORD COUNT'][num-1] = round(li[8], 2)\n",
      "<ipython-input-21-f357201dfcb0>:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  answer_df['WORD COUNT'][num-1] = round(li[9], 2)\n",
      "<ipython-input-21-f357201dfcb0>:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  answer_df['SYLLABLE PER WORD'][num-1] = round(li[10], 2)\n",
      "<ipython-input-21-f357201dfcb0>:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  answer_df['PERSONAL PRONOUNS'][num-1] = round(li[11], 2)\n",
      "<ipython-input-21-f357201dfcb0>:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  answer_df['AVG WORD LENGTH'][num-1] = round(li[12], 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 done\n",
      "2 done\n",
      "3 done\n",
      "4 done\n",
      "5 done\n",
      "6 done\n",
      "7 done\n",
      "8 done\n",
      "9 done\n",
      "10 done\n",
      "11 done\n",
      "12 done\n",
      "13 done\n",
      "14 done\n",
      "15 done\n",
      "16 done\n",
      "17 done\n",
      "18 done\n",
      "19 done\n",
      "20 done\n",
      "21 done\n",
      "22 done\n",
      "23 done\n",
      "24 done\n",
      "25 done\n",
      "26 done\n",
      "27 done\n",
      "28 done\n",
      "29 done\n",
      "30 done\n",
      "31 done\n",
      "32 done\n",
      "33 done\n",
      "34 done\n",
      "35 done\n",
      "36 done\n",
      "37 done\n",
      "38 done\n",
      "39 done\n",
      "40 done\n",
      "41 done\n",
      "42 done\n",
      "43 done\n",
      "44 done\n",
      "45 done\n",
      "46 done\n",
      "47 done\n",
      "48 done\n",
      "49 done\n",
      "50 done\n",
      "51 done\n",
      "52 done\n",
      "53 done\n",
      "54 done\n",
      "55 done\n",
      "56 done\n",
      "57 done\n",
      "58 done\n",
      "59 done\n",
      "60 done\n",
      "61 done\n",
      "62 done\n",
      "63 done\n",
      "64 done\n",
      "65 done\n",
      "66 done\n",
      "67 done\n",
      "68 done\n",
      "69 done\n",
      "70 done\n",
      "71 done\n",
      "72 done\n",
      "73 done\n",
      "74 done\n",
      "75 done\n",
      "76 done\n",
      "77 done\n",
      "78 done\n",
      "79 done\n",
      "80 done\n",
      "81 done\n",
      "82 done\n",
      "83 done\n",
      "84 done\n",
      "85 done\n",
      "86 done\n",
      "87 done\n",
      "88 done\n",
      "89 done\n",
      "90 done\n",
      "91 done\n",
      "92 done\n",
      "93 done\n",
      "94 done\n",
      "95 done\n",
      "96 done\n",
      "97 done\n",
      "98 done\n",
      "99 done\n",
      "100 done\n",
      "101 done\n",
      "102 done\n",
      "103 done\n",
      "104 done\n",
      "105 done\n",
      "106 done\n",
      "107 done\n",
      "108 done\n",
      "109 done\n",
      "110 done\n",
      "111 done\n",
      "112 done\n",
      "113 done\n",
      "114 done\n",
      "115 done\n",
      "116 done\n",
      "117 done\n",
      "118 done\n",
      "119 done\n",
      "120 done\n",
      "121 done\n",
      "122 done\n",
      "123 done\n",
      "124 done\n",
      "125 done\n",
      "126 done\n",
      "127 done\n",
      "128 done\n",
      "129 done\n",
      "130 done\n",
      "131 done\n",
      "132 done\n",
      "133 done\n",
      "134 done\n",
      "135 done\n",
      "136 done\n",
      "137 done\n",
      "138 done\n",
      "139 done\n",
      "140 done\n",
      "141 done\n",
      "142 done\n",
      "143 done\n",
      "144 done\n",
      "145 done\n",
      "146 done\n",
      "147 done\n",
      "148 done\n",
      "149 done\n",
      "150 done\n"
     ]
    }
   ],
   "source": [
    "#overall code\n",
    "for num in range(1,151):\n",
    "    answer = []\n",
    "    required = []\n",
    "    df = open(f'C:\\\\Users\\\\Administrator\\\\{num}.txt','r', encoding = 'utf-8')\n",
    "    txt = df.readlines()\n",
    "    set_up = setup(txt)\n",
    "    trans = transform(set_up)\n",
    "    positive_score = pos_score(trans)      #calculates +ve score\n",
    "    negative_score = neg_score(trans)      #calculates -ve score\n",
    "    polarity_score = (positive_score - negative_score)/((positive_score + negative_score) + 0.000001)    #calculates polarity\n",
    "    subjectivity_score = (positive_score + negative_score)/ ((len(trans.split(' '))) + 0.000001)     #calculates subjectivity\n",
    "    average_sentence_length = av_sen_length(set_up)      #calculates average sentence length\n",
    "    hardwordnumber = len(hardword())                     #calculates number of complex words\n",
    "    percent_complex = hardwordnumber/count(set_up)       #calculates % of complex words\n",
    "    fog_index = 0.4 * (average_sentence_length + percent_complex)      #calculates fog index\n",
    "    average_number_of_words_per_sentence = av_sen_length(set_up)       #caculates average number of words per sentence\n",
    "    complex_word_count = hardwordnumber                            #calulates number of complex words\n",
    "    word_count = len(trans.split(' '))                              #calculates number of words in text after cleaning\n",
    "    syllableperword = syllablecountperword(trans)                  #calultes numner of syllables per word\n",
    "    pronouns_num = pronouns(set_up)\n",
    "    avwordlength = averagewordlength(set_up)\n",
    "    answer.append([positive_score, negative_score, polarity_score, subjectivity_score, average_sentence_length, percent_complex, fog_index,average_number_of_words_per_sentence, complex_word_count, word_count, syllableperword, pronouns_num, avwordlength])\n",
    "    for i in answer:\n",
    "        li = i\n",
    "   \n",
    "    #appending the variables calculated in the dataframe\n",
    "    \n",
    "    answer_df['POSITIVE SCORE'][num-1] = round(li[0], 2)\n",
    "    answer_df['NEGATIVE SCORE'][[num-1]] = round(li[1], 2)\n",
    "    answer_df['POLARITY SCORE'][num-1] = round(li[2], 2)\n",
    "    answer_df['SUBJECTIVITY SCORE'][num-1] = round(li[3], 2)\n",
    "    answer_df['AVG SENTENCE LENGTH'][num-1] = round(li[4], 2)\n",
    "    answer_df['PERCENTAGE OF COMPLEX WORDS'][num-1] = round(li[5], 2)\n",
    "    answer_df['FOG INDEX'][num-1] = round(li[6], 2)\n",
    "    answer_df['AVG NUMBER OF WORDS PER SENTENCE'][num-1] = round(li[7],2)\n",
    "    answer_df['COMPLEX WORD COUNT'][num-1] = round(li[8], 2)\n",
    "    answer_df['WORD COUNT'][num-1] = round(li[9], 2)\n",
    "    answer_df['SYLLABLE PER WORD'][num-1] = round(li[10], 2)\n",
    "    answer_df['PERSONAL PRONOUNS'][num-1] = round(li[11], 2)\n",
    "    answer_df['AVG WORD LENGTH'][num-1] = round(li[12], 2)\n",
    "    #print(trans)\n",
    "    print(num,\"done\")      #keeps a check on what file is being executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://insights.blackcoffer.com/is-telehealth...</td>\n",
       "      <td>46.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.14</td>\n",
       "      <td>28.08</td>\n",
       "      <td>0.29</td>\n",
       "      <td>11.35</td>\n",
       "      <td>28.08</td>\n",
       "      <td>198.0</td>\n",
       "      <td>413.0</td>\n",
       "      <td>2.55</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://insights.blackcoffer.com/how-telehealt...</td>\n",
       "      <td>46.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.13</td>\n",
       "      <td>17.98</td>\n",
       "      <td>0.23</td>\n",
       "      <td>7.29</td>\n",
       "      <td>17.98</td>\n",
       "      <td>222.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>2.51</td>\n",
       "      <td>39.0</td>\n",
       "      <td>5.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://insights.blackcoffer.com/is-telemedici...</td>\n",
       "      <td>88.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.11</td>\n",
       "      <td>18.97</td>\n",
       "      <td>0.30</td>\n",
       "      <td>7.71</td>\n",
       "      <td>18.97</td>\n",
       "      <td>527.0</td>\n",
       "      <td>1064.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>66.0</td>\n",
       "      <td>5.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://insights.blackcoffer.com/is-telehealth...</td>\n",
       "      <td>69.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.08</td>\n",
       "      <td>20.60</td>\n",
       "      <td>0.30</td>\n",
       "      <td>8.36</td>\n",
       "      <td>20.60</td>\n",
       "      <td>532.0</td>\n",
       "      <td>1144.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>82.0</td>\n",
       "      <td>5.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://insights.blackcoffer.com/how-people-di...</td>\n",
       "      <td>88.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.11</td>\n",
       "      <td>22.96</td>\n",
       "      <td>0.28</td>\n",
       "      <td>9.30</td>\n",
       "      <td>22.96</td>\n",
       "      <td>502.0</td>\n",
       "      <td>1068.0</td>\n",
       "      <td>2.61</td>\n",
       "      <td>90.0</td>\n",
       "      <td>5.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>146</td>\n",
       "      <td>https://insights.blackcoffer.com/blockchain-fo...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>18.77</td>\n",
       "      <td>0.22</td>\n",
       "      <td>7.59</td>\n",
       "      <td>18.77</td>\n",
       "      <td>194.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.30</td>\n",
       "      <td>46.0</td>\n",
       "      <td>5.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>147</td>\n",
       "      <td>https://insights.blackcoffer.com/the-future-of...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.07</td>\n",
       "      <td>25.25</td>\n",
       "      <td>0.22</td>\n",
       "      <td>10.19</td>\n",
       "      <td>25.25</td>\n",
       "      <td>342.0</td>\n",
       "      <td>997.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>68.0</td>\n",
       "      <td>5.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>148</td>\n",
       "      <td>https://insights.blackcoffer.com/big-data-anal...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>0.12</td>\n",
       "      <td>17.62</td>\n",
       "      <td>0.26</td>\n",
       "      <td>7.15</td>\n",
       "      <td>17.62</td>\n",
       "      <td>299.0</td>\n",
       "      <td>681.0</td>\n",
       "      <td>2.42</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>149</td>\n",
       "      <td>https://insights.blackcoffer.com/business-anal...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.11</td>\n",
       "      <td>25.14</td>\n",
       "      <td>0.32</td>\n",
       "      <td>10.19</td>\n",
       "      <td>25.14</td>\n",
       "      <td>227.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2.71</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>150</td>\n",
       "      <td>https://insights.blackcoffer.com/challenges-an...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.15</td>\n",
       "      <td>15.89</td>\n",
       "      <td>0.24</td>\n",
       "      <td>6.45</td>\n",
       "      <td>15.89</td>\n",
       "      <td>248.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>2.43</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     URL_ID                                                URL  \\\n",
       "0         1  https://insights.blackcoffer.com/is-telehealth...   \n",
       "1         2  https://insights.blackcoffer.com/how-telehealt...   \n",
       "2         3  https://insights.blackcoffer.com/is-telemedici...   \n",
       "3         4  https://insights.blackcoffer.com/is-telehealth...   \n",
       "4         5  https://insights.blackcoffer.com/how-people-di...   \n",
       "..      ...                                                ...   \n",
       "145     146  https://insights.blackcoffer.com/blockchain-fo...   \n",
       "146     147  https://insights.blackcoffer.com/the-future-of...   \n",
       "147     148  https://insights.blackcoffer.com/big-data-anal...   \n",
       "148     149  https://insights.blackcoffer.com/business-anal...   \n",
       "149     150  https://insights.blackcoffer.com/challenges-an...   \n",
       "\n",
       "     POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
       "0              46.0            10.0            0.64                0.14   \n",
       "1              46.0            16.0            0.48                0.13   \n",
       "2              88.0            28.0            0.52                0.11   \n",
       "3              69.0            24.0            0.48                0.08   \n",
       "4              88.0            34.0            0.44                0.11   \n",
       "..              ...             ...             ...                 ...   \n",
       "145            29.0            29.0            0.00                0.10   \n",
       "146            47.0            19.0            0.42                0.07   \n",
       "147            32.0            49.0           -0.21                0.12   \n",
       "148            39.0             7.0            0.70                0.11   \n",
       "149            48.0            43.0            0.05                0.15   \n",
       "\n",
       "     AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
       "0                  28.08                         0.29      11.35   \n",
       "1                  17.98                         0.23       7.29   \n",
       "2                  18.97                         0.30       7.71   \n",
       "3                  20.60                         0.30       8.36   \n",
       "4                  22.96                         0.28       9.30   \n",
       "..                   ...                          ...        ...   \n",
       "145                18.77                         0.22       7.59   \n",
       "146                25.25                         0.22      10.19   \n",
       "147                17.62                         0.26       7.15   \n",
       "148                25.14                         0.32      10.19   \n",
       "149                15.89                         0.24       6.45   \n",
       "\n",
       "     AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
       "0                               28.08               198.0       413.0   \n",
       "1                               17.98               222.0       486.0   \n",
       "2                               18.97               527.0      1064.0   \n",
       "3                               20.60               532.0      1144.0   \n",
       "4                               22.96               502.0      1068.0   \n",
       "..                                ...                 ...         ...   \n",
       "145                             18.77               194.0       558.0   \n",
       "146                             25.25               342.0       997.0   \n",
       "147                             17.62               299.0       681.0   \n",
       "148                             25.14               227.0       420.0   \n",
       "149                             15.89               248.0       590.0   \n",
       "\n",
       "     SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
       "0                 2.55               22.0             5.60  \n",
       "1                 2.51               39.0             5.07  \n",
       "2                 2.65               66.0             5.76  \n",
       "3                 2.50               82.0             5.88  \n",
       "4                 2.61               90.0             5.68  \n",
       "..                 ...                ...              ...  \n",
       "145               2.30               46.0             5.49  \n",
       "146               2.31               68.0             5.30  \n",
       "147               2.42               31.0             5.22  \n",
       "148               2.71               24.0             5.79  \n",
       "149               2.43               40.0             5.13  \n",
       "\n",
       "[150 rows x 15 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_df      #final output table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the output table\n",
    "\n",
    "answer_df.to_csv(r\"C:\\IIT BSc. Data Science and Programming\\Internships\\Final_Ouput.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
